{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLVxL7Anquicbpyxv32F89",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarvesh2000/Stock-Predection-Web-App/blob/main/FINAL_Stock_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9ClIjupapJx"
      },
      "source": [
        "### Data Collection\n",
        "import pandas_datareader as pdr\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "key=\"483bd89d87mshce534f1bd4ba6b0p182fcdjsnf08d8fc19c04\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CVJzn8Ibjvm"
      },
      "source": [
        "def get_data(symbol):\n",
        "\n",
        "    #load the data\n",
        "    if symbol.upper() == 'AMZN':\n",
        "        df = pd.read_csv(\"AMZN.csv\")\n",
        "    elif symbol.upper() == 'TSLA':\n",
        "        df = pd.read_csv(\"TSLA.csv\")\n",
        "    elif symbol.upper() == 'GOOG':\n",
        "        df = pd.read_csv(\"GOOG.csv\")\n",
        "    elif symbol.upper() == 'AAPL':\n",
        "        df = pd.read_csv(\"AAPL.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqrOZZOHbM8D"
      },
      "source": [
        "def predict(symbol):\n",
        "    df = pdr.get_data_yahoo(symbol)\n",
        "    df1 = df. reset_index()['Close']\n",
        "    scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    df1 = scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
        "    return plt.plot(df1)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHB7k0ZEcZkz"
      },
      "source": [
        "df = pdr.get_data_yahoo('IDEA.NS')\n",
        "df1 = df. reset_index()['Close']\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIy1Wldyce3i"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch0_VLV5eOQQ"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eptzGx1se8sc"
      },
      "source": [
        "training_size=int(len(df1)*0.65)\n",
        "test_size=len(df1)-training_size\n",
        "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T0TrWlVgTc-"
      },
      "source": [
        "import numpy\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, time_step=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-time_step-1):\n",
        "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + time_step, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbEpLvDUhxb3"
      },
      "source": [
        "time_step = 100\n",
        "X_train, y_train = create_dataset(train_data, time_step)\n",
        "X_test, ytest = create_dataset(test_data, time_step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuyBTz4sjGyy"
      },
      "source": [
        "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
        "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGPsq-YfjjSL"
      },
      "source": [
        "### Create the Stacked LSTM model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XurtcezkKRg"
      },
      "source": [
        "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
        "model=Sequential()\n",
        "model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qHoH4H1k0ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d86a2ab-0ed6-409c-b4c9-377325ed64ab"
      },
      "source": [
        "\n",
        "model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=300,batch_size=64,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 0.1033 - val_loss: 0.0213\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0136 - val_loss: 0.0212\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0070 - val_loss: 0.0169\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0167\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0088\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0038 - val_loss: 0.0067\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0032 - val_loss: 0.0032\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0029 - val_loss: 0.0015\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 6.8229e-04\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0027 - val_loss: 6.0308e-04\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0026 - val_loss: 5.6914e-04\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 5.3810e-04\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 6.1061e-04\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0024 - val_loss: 5.3318e-04\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0024 - val_loss: 5.4645e-04\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 5.8219e-04\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 5.4482e-04\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0022 - val_loss: 6.0557e-04\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0022 - val_loss: 5.8877e-04\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 5.9371e-04\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0021 - val_loss: 5.5639e-04\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0021 - val_loss: 5.7733e-04\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0021 - val_loss: 4.6410e-04\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0020 - val_loss: 6.2985e-04\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0019 - val_loss: 4.2842e-04\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0018 - val_loss: 3.8573e-04\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 3.7873e-04\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 3.3096e-04\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 3.4394e-04\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 2.3462e-04\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 2.1662e-04\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0015 - val_loss: 2.2164e-04\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 2.0722e-04\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 2.2247e-04\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 2.1418e-04\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 2.0952e-04\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 2.2871e-04\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0014 - val_loss: 2.2049e-04\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 2.4895e-04\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 2.0815e-04\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 2.1253e-04\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 2.4241e-04\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 2.0072e-04\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0015 - val_loss: 2.1926e-04\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 1.9571e-04\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 2.0081e-04\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0013 - val_loss: 1.9463e-04\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 2.2364e-04\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 1.8615e-04\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 2.1801e-04\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 1.9321e-04\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0013 - val_loss: 2.0544e-04\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 1.8414e-04\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 1.9222e-04\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 1.8782e-04\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 1.8348e-04\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 0.0011 - val_loss: 1.7454e-04\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 1.9197e-04\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 1.7628e-04\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 1.7942e-04\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 1.8028e-04\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0014 - val_loss: 1.8775e-04\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 1.7434e-04\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 1.8480e-04\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 1.7120e-04\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 0.0011 - val_loss: 1.7509e-04\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 1.6569e-04\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 9.7018e-04 - val_loss: 1.8043e-04\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0010 - val_loss: 1.6407e-04\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 9.6343e-04 - val_loss: 1.6488e-04\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 1.7265e-04\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 9.8325e-04 - val_loss: 1.7536e-04\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 9.3012e-04 - val_loss: 1.7230e-04\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 9.1779e-04 - val_loss: 1.7746e-04\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 9.4363e-04 - val_loss: 1.5580e-04\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 8.8180e-04 - val_loss: 1.5554e-04\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 0.0010 - val_loss: 1.7730e-04\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 9.6069e-04 - val_loss: 1.6715e-04\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 9.1215e-04 - val_loss: 1.5411e-04\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 9.1102e-04 - val_loss: 1.6364e-04\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 8.7577e-04 - val_loss: 1.5117e-04\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 8.0908e-04 - val_loss: 1.5206e-04\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 8.4386e-04 - val_loss: 1.4535e-04\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 8.3095e-04 - val_loss: 1.4526e-04\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 8.8369e-04 - val_loss: 1.4970e-04\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 7.7175e-04 - val_loss: 1.4877e-04\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 7.7581e-04 - val_loss: 1.4680e-04\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 7.8017e-04 - val_loss: 1.4032e-04\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 7.3795e-04 - val_loss: 1.5544e-04\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 7.4523e-04 - val_loss: 1.4341e-04\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 7.3210e-04 - val_loss: 1.4001e-04\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 8.1012e-04 - val_loss: 1.3905e-04\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 8.5947e-04 - val_loss: 1.4907e-04\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 7.1192e-04 - val_loss: 1.4428e-04\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 7.0675e-04 - val_loss: 1.4700e-04\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 7.4663e-04 - val_loss: 1.4441e-04\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 7.0935e-04 - val_loss: 1.6703e-04\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 7.8294e-04 - val_loss: 1.3974e-04\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 6.9846e-04 - val_loss: 1.4616e-04\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 7.3460e-04 - val_loss: 1.5103e-04\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 6.4401e-04 - val_loss: 1.4260e-04\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 6.1713e-04 - val_loss: 1.3926e-04\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 6.5286e-04 - val_loss: 1.2836e-04\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 6.2047e-04 - val_loss: 1.3081e-04\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.9783e-04 - val_loss: 1.3608e-04\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 6.0344e-04 - val_loss: 1.2646e-04\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 6.3490e-04 - val_loss: 1.2710e-04\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 7.0400e-04 - val_loss: 1.2925e-04\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 5.8803e-04 - val_loss: 1.3630e-04\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 5.7685e-04 - val_loss: 1.4015e-04\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.7657e-04 - val_loss: 1.2379e-04\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 6.3207e-04 - val_loss: 1.2983e-04\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.6512e-04 - val_loss: 1.5568e-04\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.7639e-04 - val_loss: 1.1996e-04\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.4796e-04 - val_loss: 1.2032e-04\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 7.3142e-04 - val_loss: 1.7360e-04\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 6.7453e-04 - val_loss: 1.5248e-04\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 7.8012e-04 - val_loss: 1.2371e-04\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.8342e-04 - val_loss: 1.2964e-04\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 6.4513e-04 - val_loss: 1.5012e-04\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 6.0490e-04 - val_loss: 1.6082e-04\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.8957e-04 - val_loss: 1.3722e-04\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 5.5045e-04 - val_loss: 1.2901e-04\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.3268e-04 - val_loss: 1.1585e-04\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 6.0693e-04 - val_loss: 1.1339e-04\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.5327e-04 - val_loss: 1.1626e-04\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.0983e-04 - val_loss: 1.1764e-04\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 5.2738e-04 - val_loss: 1.2194e-04\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.6655e-04 - val_loss: 1.0990e-04\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 5.7178e-04 - val_loss: 1.1243e-04\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 5.1796e-04 - val_loss: 1.1079e-04\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.8854e-04 - val_loss: 1.1382e-04\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.0625e-04 - val_loss: 1.0874e-04\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.7796e-04 - val_loss: 1.0797e-04\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 6.7560e-04 - val_loss: 1.1366e-04\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 6.5009e-04 - val_loss: 1.1045e-04\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.5906e-04 - val_loss: 1.0947e-04\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.3167e-04 - val_loss: 1.0704e-04\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.6566e-04 - val_loss: 1.1472e-04\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 4.7966e-04 - val_loss: 1.2483e-04\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.9549e-04 - val_loss: 1.0688e-04\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 7.3881e-04 - val_loss: 1.1559e-04\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 6.3522e-04 - val_loss: 1.3062e-04\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.9312e-04 - val_loss: 1.2278e-04\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.6789e-04 - val_loss: 1.2563e-04\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 4.8517e-04 - val_loss: 1.0826e-04\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 5.1998e-04 - val_loss: 1.0416e-04\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.8000e-04 - val_loss: 1.0346e-04\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.8242e-04 - val_loss: 1.0191e-04\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.4186e-04 - val_loss: 1.0219e-04\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 4.3190e-04 - val_loss: 1.0023e-04\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.2041e-04 - val_loss: 9.9688e-05\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.3047e-04 - val_loss: 9.7675e-05\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.4992e-04 - val_loss: 9.6320e-05\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.6449e-04 - val_loss: 9.7154e-05\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.2461e-04 - val_loss: 9.5883e-05\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 4.1555e-04 - val_loss: 9.6238e-05\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 4.6813e-04 - val_loss: 9.6639e-05\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.3095e-04 - val_loss: 1.0684e-04\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.2178e-04 - val_loss: 9.6525e-05\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.4880e-04 - val_loss: 9.8377e-05\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.7037e-04 - val_loss: 1.0589e-04\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 6.0811e-04 - val_loss: 9.8033e-05\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.7402e-04 - val_loss: 9.6408e-05\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.2687e-04 - val_loss: 9.4819e-05\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.3173e-04 - val_loss: 9.4784e-05\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.3218e-04 - val_loss: 9.7260e-05\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.1660e-04 - val_loss: 9.3135e-05\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.9337e-04 - val_loss: 9.7777e-05\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.9060e-04 - val_loss: 9.5607e-05\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 4.0007e-04 - val_loss: 9.6652e-05\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.8657e-04 - val_loss: 9.3043e-05\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.9499e-04 - val_loss: 9.0451e-05\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.7741e-04 - val_loss: 9.3922e-05\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 4.0802e-04 - val_loss: 9.6105e-05\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.7657e-04 - val_loss: 9.0797e-05\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.6474e-04 - val_loss: 9.0158e-05\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.5021e-04 - val_loss: 1.0408e-04\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.7485e-04 - val_loss: 8.9852e-05\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.2314e-04 - val_loss: 8.8935e-05\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.0104e-04 - val_loss: 8.8036e-05\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.9201e-04 - val_loss: 8.8438e-05\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.0319e-04 - val_loss: 8.9348e-05\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 3.9747e-04 - val_loss: 9.0121e-05\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.9027e-04 - val_loss: 9.2571e-05\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5272e-04 - val_loss: 8.6197e-05\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5467e-04 - val_loss: 8.7965e-05\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.5770e-04 - val_loss: 8.8759e-05\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.9969e-04 - val_loss: 8.5677e-05\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.6437e-04 - val_loss: 1.0273e-04\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.6560e-04 - val_loss: 8.5941e-05\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.6712e-04 - val_loss: 8.5477e-05\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.4992e-04 - val_loss: 8.6690e-05\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.6570e-04 - val_loss: 8.5599e-05\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.5783e-04 - val_loss: 8.7966e-05\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.6328e-04 - val_loss: 1.0474e-04\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 4.4507e-04 - val_loss: 8.7625e-05\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.4853e-04 - val_loss: 8.7984e-05\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5953e-04 - val_loss: 9.2607e-05\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.7093e-04 - val_loss: 8.3541e-05\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.1362e-04 - val_loss: 8.5233e-05\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.0230e-04 - val_loss: 9.7248e-05\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.7587e-04 - val_loss: 8.7669e-05\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.7577e-04 - val_loss: 9.0047e-05\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.7106e-04 - val_loss: 9.0236e-05\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.7289e-04 - val_loss: 8.3782e-05\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.9139e-04 - val_loss: 9.8039e-05\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.9673e-04 - val_loss: 9.8759e-05\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5143e-04 - val_loss: 8.3402e-05\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 3.5776e-04 - val_loss: 9.0016e-05\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5589e-04 - val_loss: 9.5105e-05\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5463e-04 - val_loss: 9.5309e-05\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.3497e-04 - val_loss: 8.3144e-05\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.2021e-04 - val_loss: 8.0854e-05\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.2458e-04 - val_loss: 9.4866e-05\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5265e-04 - val_loss: 9.7570e-05\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.6367e-04 - val_loss: 8.2579e-05\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.9732e-04 - val_loss: 9.2434e-05\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.1327e-04 - val_loss: 8.3751e-05\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.1741e-04 - val_loss: 8.1827e-05\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.9059e-04 - val_loss: 8.6576e-05\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.5841e-04 - val_loss: 8.4039e-05\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.2727e-04 - val_loss: 8.3853e-05\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.1027e-04 - val_loss: 8.8601e-05\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.0894e-04 - val_loss: 8.8011e-05\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.7813e-04 - val_loss: 7.9123e-05\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.3641e-04 - val_loss: 8.3154e-05\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5444e-04 - val_loss: 7.8876e-05\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5543e-04 - val_loss: 8.7492e-05\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.0630e-04 - val_loss: 8.8381e-05\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.9970e-04 - val_loss: 7.9779e-05\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 4.3299e-04 - val_loss: 1.0318e-04\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.0615e-04 - val_loss: 1.0510e-04\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.2256e-04 - val_loss: 8.7658e-05\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.2768e-04 - val_loss: 7.8850e-05\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.1681e-04 - val_loss: 8.8622e-05\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.1010e-04 - val_loss: 8.2445e-05\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.4081e-04 - val_loss: 1.0031e-04\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.6420e-04 - val_loss: 8.1107e-05\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.7494e-04 - val_loss: 1.1463e-04\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 3.1336e-04 - val_loss: 1.0736e-04\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.4736e-04 - val_loss: 7.7986e-05\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.4081e-04 - val_loss: 1.0512e-04\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.7259e-04 - val_loss: 1.0282e-04\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.1059e-04 - val_loss: 8.3843e-05\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.7504e-04 - val_loss: 7.9286e-05\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.3887e-04 - val_loss: 8.0971e-05\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.1244e-04 - val_loss: 8.5900e-05\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 3.0942e-04 - val_loss: 8.5118e-05\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.7599e-04 - val_loss: 9.8086e-05\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5783e-04 - val_loss: 7.9596e-05\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 3.6757e-04 - val_loss: 9.1737e-05\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.1917e-04 - val_loss: 8.6706e-05\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.0538e-04 - val_loss: 9.2472e-05\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 4.0481e-04 - val_loss: 7.9634e-05\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.4863e-04 - val_loss: 8.2041e-05\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.3441e-04 - val_loss: 9.6030e-05\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.2610e-04 - val_loss: 8.3976e-05\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.4026e-04 - val_loss: 1.0404e-04\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5565e-04 - val_loss: 8.0481e-05\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.4926e-04 - val_loss: 8.4816e-05\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5594e-04 - val_loss: 8.3687e-05\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.6855e-04 - val_loss: 9.1308e-05\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.6468e-04 - val_loss: 9.6627e-05\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.5223e-04 - val_loss: 1.0367e-04\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.2906e-04 - val_loss: 8.4517e-05\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 3.0901e-04 - val_loss: 8.3939e-05\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.0686e-04 - val_loss: 1.0339e-04\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.1607e-04 - val_loss: 9.8276e-05\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 5.1375e-04 - val_loss: 8.9973e-05\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 4.6974e-04 - val_loss: 1.0888e-04\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5528e-04 - val_loss: 7.9578e-05\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 3.2925e-04 - val_loss: 1.0283e-04\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.0572e-04 - val_loss: 1.0256e-04\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.4594e-04 - val_loss: 1.0129e-04\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.1377e-04 - val_loss: 1.1248e-04\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.2145e-04 - val_loss: 1.0963e-04\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 3.2958e-04 - val_loss: 1.1143e-04\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.2011e-04 - val_loss: 1.0922e-04\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.1063e-04 - val_loss: 1.0161e-04\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.5471e-04 - val_loss: 1.1672e-04\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.2911e-04 - val_loss: 8.4501e-05\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.2267e-04 - val_loss: 8.6061e-05\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.2113e-04 - val_loss: 9.6713e-05\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 2.9924e-04 - val_loss: 1.1233e-04\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.1415e-04 - val_loss: 9.7754e-05\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.3662e-04 - val_loss: 8.4693e-05\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 4.0484e-04 - val_loss: 9.6541e-05\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.9089e-04 - val_loss: 9.0031e-05\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.2091e-04 - val_loss: 9.3396e-05\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.2453e-04 - val_loss: 9.9668e-05\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.1107e-04 - val_loss: 9.7589e-05\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.1183e-04 - val_loss: 8.7405e-05\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.1764e-04 - val_loss: 9.6004e-05\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 3.8032e-04 - val_loss: 1.0780e-04\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.2581e-04 - val_loss: 1.2922e-04\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.3943e-04 - val_loss: 1.1110e-04\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 21ms/step - loss: 3.1255e-04 - val_loss: 1.0497e-04\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 3.1617e-04 - val_loss: 1.1178e-04\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 19ms/step - loss: 3.0780e-04 - val_loss: 9.8434e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb3fecc2748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BFgADBplB4h"
      },
      "source": [
        "train_predict=model.predict(X_train)\n",
        "test_predict=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKErv0Qil3_Y"
      },
      "source": [
        "##Transformback to original form --- rescaling\n",
        "train_predict=scaler.inverse_transform(train_predict)\n",
        "test_predict=scaler.inverse_transform(test_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEuZTGgrmWEi"
      },
      "source": [
        "\n",
        "### Plotting\n",
        "# shift train predictions for plotting\n",
        "look_back=100\n",
        "trainPredictPlot = numpy.empty_like(df1)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(df1)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO63e8Jzn6Ix"
      },
      "source": [
        "x_input = test_data[331:].reshape(1,-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djLetqdSoKhS"
      },
      "source": [
        "temp_input = list(x_input)\n",
        "temp_input = temp_input[0].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV8cPFLlojjT"
      },
      "source": [
        "# demonstrate prediction for next 10 days\n",
        "from numpy import array\n",
        "\n",
        "lst_output=[]\n",
        "n_steps=100\n",
        "i=0\n",
        "while(i<3):\n",
        "\n",
        "    if(len(temp_input)>100):\n",
        "\n",
        "        x_input=np.array(temp_input[1:])\n",
        "\n",
        "        x_input=x_input.reshape(1,-1)\n",
        "        x_input = x_input.reshape((1, n_steps, 1))\n",
        "\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        temp_input=temp_input[1:]\n",
        "\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps,1))\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkxjV0Y0oqug"
      },
      "source": [
        "\n",
        "day_new=np.arange(1,101) #testdata 100indexes\n",
        "day_pred=np.arange(101,104) #101-131-predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwiNJ-MqpZu1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "775732a1-86ac-4eb0-ba9c-8c92ed3ccd6a"
      },
      "source": [
        "\n",
        "plt.plot(day_new,scaler.inverse_transform(df1[1131:]))\n",
        "plt.plot(day_pred,scaler.inverse_transform(lst_output))\n",
        "plt.savefig('saved_figure.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G3PfYnWbahA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af50fdf1-8c27-44a1-9eb3-c889fe7e0273"
      },
      "source": [
        "lst_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.06965700536966324], [0.06982079893350601], [0.07045244425535202]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuEgvdHvbcu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956bf056-bc0b-41a1-bb17-e51db951d96f"
      },
      "source": [
        "df1[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.06776018])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMzd5RfTb3AR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bd920eb-f227-44fd-d339-e03f933fafe2"
      },
      "source": [
        "plt.savefig('Predicted.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlPMuJ9lsl7H"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}